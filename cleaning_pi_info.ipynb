{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning PI Info\n",
    "In order to prevent duplicate information used to train a model, store PI information separately from list of features.\n",
    "\n",
    "**Eventually store as SQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import cleaning_strings as cln\n",
    "import importlib as imp\n",
    "imp.reload(cln);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_zero_zip(df, length, col1 = 'org_zipcode', col2 = 'org_country', country = 'united states'):\n",
    "    \n",
    "    '''Add leading zero to New England zipcodes.\n",
    "    Arguments are the df and length of incorrect zipcode.\n",
    "    Returns two lists, one with the original zipcodes and one with the added leading zero.'''\n",
    "    \n",
    "    original = []\n",
    "    actual = []\n",
    "    for num in df.ix[(df[col1].str.len() == length) & (df[col2].str.contains(country))][col1]:\n",
    "        original.append(num)\n",
    "        num = '0' + num\n",
    "        actual.append(num)\n",
    "    return original, actual\n",
    "\n",
    "def add_zero_duns(df, col1 = 'org_duns'):\n",
    "    \n",
    "    '''Add leading zeros to DUNS numbers until DUNS number is 9 digits.\n",
    "    Returns the df with leading zeros added to short DUNS numbers.'''\n",
    "    \n",
    "    actual = []\n",
    "    series = df[col1].tolist()\n",
    "    for num in series:\n",
    "        \n",
    "        #skip null entries\n",
    "        if type(num) == float:\n",
    "            pass\n",
    "        \n",
    "        #add zeros until length is 9\n",
    "        else:\n",
    "            while len(num) < 9.0:\n",
    "                num = '0' + num\n",
    "        actual.append(num)\n",
    "    \n",
    "    #add new column to df with 9 digit DUNS numbers\n",
    "    df[col1 + '_'] = actual\n",
    "    \n",
    "    #delete original column and rename new column\n",
    "    del df[col1]\n",
    "    df = df.rename(columns = {col1 + '_':col1})\n",
    "    return df\n",
    "\n",
    "def get_unique_values(df, name, col_filter = 'org_duns'):\n",
    "    \n",
    "    '''Get unique values in each column to be filled for a particular entry.\n",
    "    Takes a df, the name of the column to be filtered, and the name of the entry.\n",
    "    Returns the dictionary where the keys are the columns to be filled and the\n",
    "    values are the unique values for the entry.\n",
    "    Also returns a list of the non-unique organization names that match an individual DUNS number.'''\n",
    "    \n",
    "    #create list of columns to fill\n",
    "    cols_to_fill = 'org_duns org_name org_city org_state org_zipcode org_country'.split()\n",
    "    \n",
    "    #create dictionary where keys are the column names\n",
    "    cols_dict = {key: None for key in cols_to_fill}\n",
    "    \n",
    "    #filter rows by element (name) in column to be filtered (col_filter)\n",
    "    values = df.ix[df[col_filter] == name]\n",
    "    \n",
    "    #want to match each column name (key) with the correct entry (value)\n",
    "    for col in cols_to_fill:\n",
    "        \n",
    "        #get the unique values of each column to fill\n",
    "        unique_value = values[col].dropna().unique()\n",
    "        \n",
    "        #check there is only 1 unique value and match with key\n",
    "        if unique_value.shape == (1,):\n",
    "            cols_dict[col] = unique_value[0]\n",
    "        \n",
    "        #check if array is empty\n",
    "        elif unique_value.shape == (0,):\n",
    "            cols_dict[col] = np.nan\n",
    "        \n",
    "        else:\n",
    "            #fill value with most frequently occurring value\n",
    "            #assumption is most frequently occurring value is the correct value\n",
    "            cols_dict[col] = values[col].value_counts().idxmax()\n",
    "            \n",
    "            #print out org_names to check whether individual DUNS match multiple org_names\n",
    "            #for diagnostic purposes\n",
    "            #if col == 'org_name':\n",
    "                #print(unique_value)\n",
    "    return cols_dict\n",
    "\n",
    "def fill_missing(df, col_filter = 'org_duns'):\n",
    "    \n",
    "    '''Fill missing values in each grant based on the unique DUNS number.\n",
    "    Returns a df.'''\n",
    "    \n",
    "    #get list of unique entries (default is unique DUNS numbers)\n",
    "    list_unique = df[col_filter].dropna().unique().tolist()\n",
    "    df_new = pd.DataFrame(columns = df.columns)\n",
    "    \n",
    "    #for every DUNS number:\n",
    "    for i in list_unique:\n",
    "        #fill null values in each column with corresponding unique values\n",
    "        to_fill = get_unique_values(df, i, col_filter)\n",
    "        df_append = df.ix[df[col_filter] == i].fillna(to_fill)\n",
    "        df_new = df_new.append(df_append)\n",
    "    df_new = df_new.sort_index()\n",
    "    return df_new\n",
    "\n",
    "def merge_fill_nans(df1, df2, col):\n",
    "    \n",
    "    '''Merge two dfs and fill NaNs in the first df with values from the duplicated column\n",
    "    in the second df. Drop the duplicate column.\n",
    "    Returns a df.'''\n",
    "    \n",
    "    #merge the original df and the new df and fill NaNs\n",
    "    df_merged = pd.merge(df1, df2, how = 'left', left_index = True, right_index = True, suffixes = ('', '_copy'))\n",
    "    df_merged[col].fillna(df_merged[col + '_copy'], inplace = True)\n",
    "    \n",
    "    #remove duplicate columns\n",
    "    to_keep = [col for col in df1.columns if '_copy' not in col]\n",
    "    df_merged = df_merged[to_keep]\n",
    "    return df_merged\n",
    "\n",
    "def add_dummy_duns(df, col_filter1 = 'org_duns', col_filter2 = 'org_name'):\n",
    "    \n",
    "    '''Fill missing DUNS numbers with dummy 9 digit number.\n",
    "    Returns a df with all DUNS filled in.'''\n",
    "    \n",
    "    #extract entries where DUNS is not listed\n",
    "    nulls = df.ix[df[col_filter1].isnull()]\n",
    "    null_names = nulls[col_filter2].unique().tolist()\n",
    "    df_replace = []\n",
    "    \n",
    "    #for each institute where the DUNS is not listed\n",
    "    for i in null_names:\n",
    "        #generate a random DUNS number; no original DUNS is listed with 4 leading zeros.\n",
    "        dummy = '0000' + str(randint(10000, 99999))\n",
    "        #create a series where the DUNS number per institute is filled in\n",
    "        df_fill = pd.DataFrame(df.ix[df[col_filter2] == i][col_filter1].fillna(dummy))\n",
    "        df_replace.append(df_fill)\n",
    "    \n",
    "    #concatenate the list of series into a dataframe\n",
    "    df_replace = pd.concat(df_replace)\n",
    "    df_merged = merge_fill_nans(df, df_replace, col_filter1)\n",
    "    return df_merged\n",
    "\n",
    "def replace_info(df, col_filter = 'org_duns', all_cols = ['org_name', 'org_city',\n",
    "                                                          'org_state', 'org_zipcode']):\n",
    "    \n",
    "    '''Replace incorrect information.'''\n",
    "    \n",
    "    duns_list = df[col_filter].unique().tolist()\n",
    "    df_new = []\n",
    "    for duns in duns_list:\n",
    "        subset = df.ix[df[col_filter] == duns]\n",
    "        for col in all_cols:\n",
    "            values = subset[col].value_counts(dropna = False)\n",
    "            to_replace = values.index.tolist()\n",
    "            replacement = values.idxmax()\n",
    "            subset[col] = subset[col].replace(to_replace, replacement)\n",
    "        df_new.append(subset)\n",
    "    df_new = pd.concat(df_new)\n",
    "    df_new.sort_index(inplace = True)\n",
    "    return df_new\n",
    "\n",
    "def replace_nih_info(df, dict_, org_name = 'org_name'):\n",
    "    \n",
    "    '''Some NIH centers have updated names.\n",
    "    Replace the appropriate grants with this information.\n",
    "    Returns a df.'''\n",
    "    \n",
    "    for k, v in dict_.items():\n",
    "        df.replace({k:v}, inplace = True)\n",
    "        df.ix[df[org_name] == v] = df.ix[df[org_name] == v].fillna(method = 'bfill').fillna(method = 'ffill')\n",
    "    return df\n",
    "\n",
    "def add_nih_info(df, col, replace_with, org_name = 'org_name', org_country = 'org_country'):\n",
    "    \n",
    "    '''Add missing NIH information. These are NIH centers where no information is listed other\n",
    "    than the organization name.\n",
    "    Returns a df.'''\n",
    "    \n",
    "    #NIH institutes are those where the org_name is listed but the country is not\n",
    "    df_replace = pd.DataFrame(df.ix[~df[org_name].isnull() & df[org_country].isnull()]\\\n",
    "                              [col].fillna(replace_with))\n",
    "    df_merged = merge_fill_nans(df, df_replace, col)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning PI information\n",
    "We want a dataframe where each row is a single PI (no duplicates) and associated organization information as a cross-reference to the grants data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant columns from csv with raw grant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = 'fy pi_ids pi_names org_name org_city org_state org_country org_zipcode org_duns'.split()\n",
    "dtypes = {key: str for key in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>org_city</th>\n",
       "      <th>org_country</th>\n",
       "      <th>org_duns</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_state</th>\n",
       "      <th>org_zipcode</th>\n",
       "      <th>pi_ids</th>\n",
       "      <th>pi_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2223287</th>\n",
       "      <td>2016</td>\n",
       "      <td>lawrence</td>\n",
       "      <td>united states</td>\n",
       "      <td>76248616</td>\n",
       "      <td>university of kansas lawrence</td>\n",
       "      <td>ks</td>\n",
       "      <td>660457568</td>\n",
       "      <td>8097</td>\n",
       "      <td>mcgill, jodi l.;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223288</th>\n",
       "      <td>2016</td>\n",
       "      <td>davis</td>\n",
       "      <td>united states</td>\n",
       "      <td>47120084</td>\n",
       "      <td>university of california at davis</td>\n",
       "      <td>ca</td>\n",
       "      <td>956186153</td>\n",
       "      <td>8097</td>\n",
       "      <td>clancy, colleen e;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223289</th>\n",
       "      <td>2016</td>\n",
       "      <td>la jolla</td>\n",
       "      <td>united states</td>\n",
       "      <td>804355790</td>\n",
       "      <td>university of california san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>920930934</td>\n",
       "      <td>8097</td>\n",
       "      <td>feng, gen-sheng ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223290</th>\n",
       "      <td>2016</td>\n",
       "      <td>coral gables</td>\n",
       "      <td>united states</td>\n",
       "      <td>52780918</td>\n",
       "      <td>university of miami school of medicine</td>\n",
       "      <td>fl</td>\n",
       "      <td>331462926</td>\n",
       "      <td>8097</td>\n",
       "      <td>sharifai, nima ;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223291</th>\n",
       "      <td>2016</td>\n",
       "      <td>toledo</td>\n",
       "      <td>united states</td>\n",
       "      <td>51623734</td>\n",
       "      <td>university of toledo</td>\n",
       "      <td>oh</td>\n",
       "      <td>436063390</td>\n",
       "      <td>8097</td>\n",
       "      <td>liu, song-tao ;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fy      org_city    org_country   org_duns  \\\n",
       "2223287  2016      lawrence  united states   76248616   \n",
       "2223288  2016         davis  united states   47120084   \n",
       "2223289  2016      la jolla  united states  804355790   \n",
       "2223290  2016  coral gables  united states   52780918   \n",
       "2223291  2016        toledo  united states   51623734   \n",
       "\n",
       "                                       org_name org_state org_zipcode pi_ids  \\\n",
       "2223287           university of kansas lawrence        ks   660457568   8097   \n",
       "2223288       university of california at davis        ca   956186153   8097   \n",
       "2223289      university of california san diego        ca   920930934   8097   \n",
       "2223290  university of miami school of medicine        fl   331462926   8097   \n",
       "2223291                    university of toledo        oh   436063390   8097   \n",
       "\n",
       "                   pi_names  \n",
       "2223287    mcgill, jodi l.;  \n",
       "2223288  clancy, colleen e;  \n",
       "2223289   feng, gen-sheng ;  \n",
       "2223290    sharifai, nima ;  \n",
       "2223291     liu, song-tao ;  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_info_raw = pd.read_csv('all_grants.csv', compression = 'gzip', usecols = columns, dtype = dtypes)\n",
    "\n",
    "#Only analyzing grants from 2000 onwards, as prior to that no funding information is available\n",
    "pi_info_raw = pi_info_raw.ix[pi_info_raw['fy'] >= '2009']\n",
    "pi_info_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>org_city</th>\n",
       "      <th>org_country</th>\n",
       "      <th>org_duns</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_state</th>\n",
       "      <th>org_zipcode</th>\n",
       "      <th>pi_ids</th>\n",
       "      <th>pi_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2223287</th>\n",
       "      <td>2016</td>\n",
       "      <td>lawrence</td>\n",
       "      <td>united states</td>\n",
       "      <td>76248616</td>\n",
       "      <td>university of kansas lawrence</td>\n",
       "      <td>ks</td>\n",
       "      <td>660457568</td>\n",
       "      <td>8097</td>\n",
       "      <td>mcgill, jodi l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223288</th>\n",
       "      <td>2016</td>\n",
       "      <td>davis</td>\n",
       "      <td>united states</td>\n",
       "      <td>47120084</td>\n",
       "      <td>university of california at davis</td>\n",
       "      <td>ca</td>\n",
       "      <td>956186153</td>\n",
       "      <td>8097</td>\n",
       "      <td>clancy, colleen e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223289</th>\n",
       "      <td>2016</td>\n",
       "      <td>la jolla</td>\n",
       "      <td>united states</td>\n",
       "      <td>804355790</td>\n",
       "      <td>university of california san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>920930934</td>\n",
       "      <td>8097</td>\n",
       "      <td>feng, gen-sheng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223290</th>\n",
       "      <td>2016</td>\n",
       "      <td>coral gables</td>\n",
       "      <td>united states</td>\n",
       "      <td>52780918</td>\n",
       "      <td>university of miami school of medicine</td>\n",
       "      <td>fl</td>\n",
       "      <td>331462926</td>\n",
       "      <td>8097</td>\n",
       "      <td>sharifai, nima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223291</th>\n",
       "      <td>2016</td>\n",
       "      <td>toledo</td>\n",
       "      <td>united states</td>\n",
       "      <td>51623734</td>\n",
       "      <td>university of toledo</td>\n",
       "      <td>oh</td>\n",
       "      <td>436063390</td>\n",
       "      <td>8097</td>\n",
       "      <td>liu, song-tao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fy      org_city    org_country   org_duns  \\\n",
       "2223287  2016      lawrence  united states   76248616   \n",
       "2223288  2016         davis  united states   47120084   \n",
       "2223289  2016      la jolla  united states  804355790   \n",
       "2223290  2016  coral gables  united states   52780918   \n",
       "2223291  2016        toledo  united states   51623734   \n",
       "\n",
       "                                       org_name org_state org_zipcode pi_ids  \\\n",
       "2223287           university of kansas lawrence        ks   660457568   8097   \n",
       "2223288       university of california at davis        ca   956186153   8097   \n",
       "2223289      university of california san diego        ca   920930934   8097   \n",
       "2223290  university of miami school of medicine        fl   331462926   8097   \n",
       "2223291                    university of toledo        oh   436063390   8097   \n",
       "\n",
       "                  pi_names  \n",
       "2223287     mcgill, jodi l  \n",
       "2223288  clancy, colleen e  \n",
       "2223289    feng, gen-sheng  \n",
       "2223290     sharifai, nima  \n",
       "2223291      liu, song-tao  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_info_cleaned = cln.strip_df(pi_info_raw, ' ', ';', ' ', '.')\n",
    "pi_info_cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 653801 entries, 1569491 to 2223291\n",
      "Data columns (total 9 columns):\n",
      "fy             653801 non-null object\n",
      "org_city       625577 non-null object\n",
      "org_country    625632 non-null object\n",
      "org_duns       611923 non-null object\n",
      "org_name       653128 non-null object\n",
      "org_state      617661 non-null object\n",
      "org_zipcode    622758 non-null object\n",
      "pi_ids         653801 non-null object\n",
      "pi_names       653801 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 49.9+ MB\n"
     ]
    }
   ],
   "source": [
    "pi_info_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting PI Info\n",
    "Some grants have multiple PIs listed on the grant, and the information for the group of PIs is listed only as the contact PI's information. In order to get unique PI information, these PI groups must be separated into individual PIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split pi_info_cleaned into two dataframes, one containing grouped (multiple) PIs and one containing single PIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653801, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_pi_unsplit = pi_info_cleaned.ix[pi_info_cleaned['pi_ids'].str.contains('contact', na = False)]\n",
    "pi_info = pi_info_cleaned.drop(multi_pi_unsplit.index)\n",
    "pi_info.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates to obtain unique PIs that were awarded solo grants. Check both PI IDs and organization name to check for PIs that moved to a different institution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9615, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>org_city</th>\n",
       "      <th>org_country</th>\n",
       "      <th>org_duns</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_state</th>\n",
       "      <th>org_zipcode</th>\n",
       "      <th>pi_ids</th>\n",
       "      <th>pi_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2222317</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437306274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8097</td>\n",
       "      <td>cucca, francesco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222906</th>\n",
       "      <td>2016</td>\n",
       "      <td>mansfield</td>\n",
       "      <td>united states</td>\n",
       "      <td>940639748</td>\n",
       "      <td>agypharma, llc</td>\n",
       "      <td>tx</td>\n",
       "      <td>760633809</td>\n",
       "      <td>8097</td>\n",
       "      <td>nguyen, vien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222972</th>\n",
       "      <td>2016</td>\n",
       "      <td>pickerington</td>\n",
       "      <td>united states</td>\n",
       "      <td>74859047</td>\n",
       "      <td>ohio state bureau/workers' compensation</td>\n",
       "      <td>oh</td>\n",
       "      <td>431478310</td>\n",
       "      <td>8097</td>\n",
       "      <td>al-tarawneh, ibraheem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223034</th>\n",
       "      <td>2016</td>\n",
       "      <td>novato</td>\n",
       "      <td>united states</td>\n",
       "      <td>79336779</td>\n",
       "      <td>image analyst software</td>\n",
       "      <td>ca</td>\n",
       "      <td>949451775</td>\n",
       "      <td>8097</td>\n",
       "      <td>gerencser, akos a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223094</th>\n",
       "      <td>2016</td>\n",
       "      <td>san diego</td>\n",
       "      <td>united states</td>\n",
       "      <td>78884924</td>\n",
       "      <td>forge therapeutics, inc</td>\n",
       "      <td>ca</td>\n",
       "      <td>921211126</td>\n",
       "      <td>8097</td>\n",
       "      <td>puerta, david</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fy      org_city    org_country   org_duns  \\\n",
       "2222317  2016           NaN            NaN  437306274   \n",
       "2222906  2016     mansfield  united states  940639748   \n",
       "2222972  2016  pickerington  united states   74859047   \n",
       "2223034  2016        novato  united states   79336779   \n",
       "2223094  2016     san diego  united states   78884924   \n",
       "\n",
       "                                        org_name org_state org_zipcode pi_ids  \\\n",
       "2222317                                      NaN       NaN         NaN   8097   \n",
       "2222906                           agypharma, llc        tx   760633809   8097   \n",
       "2222972  ohio state bureau/workers' compensation        oh   431478310   8097   \n",
       "2223034                   image analyst software        ca   949451775   8097   \n",
       "2223094                  forge therapeutics, inc        ca   921211126   8097   \n",
       "\n",
       "                      pi_names  \n",
       "2222317       cucca, francesco  \n",
       "2222906           nguyen, vien  \n",
       "2222972  al-tarawneh, ibraheem  \n",
       "2223034      gerencser, akos a  \n",
       "2223094          puerta, david  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_unique = pi_info.drop_duplicates(['pi_ids', 'org_duns'])\n",
    "pi_unique.shape\n",
    "pi_unique.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split multiple PIs on PI ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fy</th>\n",
       "      <th>org_city</th>\n",
       "      <th>org_country</th>\n",
       "      <th>org_duns</th>\n",
       "      <th>org_name</th>\n",
       "      <th>org_state</th>\n",
       "      <th>org_zipcode</th>\n",
       "      <th>pi_ids</th>\n",
       "      <th>pi_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [fy, org_city, org_country, org_duns, org_name, org_state, org_zipcode, pi_ids, pi_names]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_pi_unsplit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dd876359535e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmulti_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_pi_unsplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pi_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmulti_pi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuwenwu/nih_awards/cleaning_strings.py\u001b[0m in \u001b[0;36msplit_rows\u001b[0;34m(df, col_name, by)\u001b[0m\n\u001b[1;32m     18\u001b[0m     '''\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdroplevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'stack'"
     ]
    }
   ],
   "source": [
    "multi_pi = cln.split_rows(multi_pi_unsplit, 'pi_ids', by = ';')\n",
    "multi_pi.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a df where the '(contact)' string has been stripped from pi_ids; this will allow identification of unique PI IDs (otherwise an ID with '(contact)' appended at the end is viewed as a unique string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "multi_stripped = multi_pi.copy()\n",
    "multi_stripped['pi_ids'] = multi_stripped['pi_ids'].str.strip(' (contact)')\n",
    "multi_stripped.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create columns in split multi_pi df denoting whether the PI is the contact and whether the PI ID is already present in the df pi_unique (which contains all PIs that are solo authors of a grant). If the PI is already in pi_unique, we do not need to separate their information again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_pi['contact'] = multi_pi['pi_ids'].str.contains('contact', na = False)\n",
    "in_pi_unique = multi_stripped['pi_ids'].isin(pi_unique['pi_ids'])\n",
    "multi_pi['unique_pi'] = in_pi_unique\n",
    "multi_pi.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One PI is always designated as a contact if there are multiple PIs listed on a grant. If the PI's ID was not in the df pi_unique, but is listed as a contact (that is, unique_pi == False but contact == True), then we can isolate their information and add this information to pi_unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_contact = multi_pi[(multi_pi['unique_pi'] == False) & (multi_pi['contact'] == True)]\n",
    "unique_contact = cln.split_rows(unique_contact, 'pi_names', ';')\n",
    "unique_contact = unique_contact[unique_contact['pi_names'].str.contains('contact')]\n",
    "unique_contact = cln.strip_series(unique_contact, ['pi_ids', 'pi_names'])\n",
    "\n",
    "#shape before dropping duplicates\n",
    "unique_contact.shape\n",
    "unique_contact = unique_contact.drop_duplicates('pi_ids org_duns'.split())\n",
    "\n",
    "#shape after dropping duplicates\n",
    "unique_contact.shape\n",
    "unique_contact.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the PI ID is neither listed in unique_pi nor are they ever listed as a contact, then we cannot identify whether their organization information is actually different from the contact PI's information. These names will therefore not be split (the IDs are already split).\n",
    "\n",
    "**Note:** When doing analysis from multiple years, PI IDs should be cross-referenced across years in case a PI did have a solo grant in one year but not in others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_contact = multi_pi[(multi_pi['unique_pi'] == False) & (multi_pi['contact'] == False)]\n",
    "not_contact = not_contact.drop_duplicates('pi_ids org_duns'.split())\n",
    "not_contact.shape\n",
    "not_contact.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join all dfs containing unique PI ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reorder columns so joins can be performed correctly\n",
    "\n",
    "#unique PIs with a solo grant\n",
    "cols1 = unique_contact.columns.tolist()\n",
    "cols1 = cols1[-4:-3] + cols1[-1:] + cols1[0:5]\n",
    "unique_1 = unique_contact[cols1]\n",
    "\n",
    "#unique PIs that neither have a solor grant nor are listed as a contact\n",
    "cols2 = not_contact.columns.tolist()\n",
    "cols2 = cols2[-3:-2] + cols2[0:6]\n",
    "unique_2 = not_contact[cols2]\n",
    "\n",
    "#unique PIs that do not have solo grants but are listed as a contact\n",
    "unique_multi = unique_1.append(unique_2)\n",
    "unique_multi = unique_multi.drop_duplicates('pi_ids org_name'.split())\n",
    "unique_multi.shape\n",
    "\n",
    "pi_unique.shape\n",
    "pi_unique = pi_unique.append(unique_multi)\n",
    "\n",
    "pi_unique = cln.strip_series(pi_unique, ['pi_ids'], strip = ' ')\n",
    "pi_unique = pi_unique.drop_duplicates('pi_ids org_name'.split())\n",
    "pi_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing zipcodes\n",
    "The leading zero of New England zipcodes was dropped in the raw data. Add leading zero to zipcodes from the US that are length 8 or 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique['org_zipcode'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_8, zip_9 = add_zero_zip(pi_unique, 8.0)\n",
    "zip_4, zip_5 = add_zero_zip(pi_unique, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique['org_zipcode'] = pi_unique['org_zipcode'].replace(zip_8, zip_9)\n",
    "pi_unique['org_zipcode'] = pi_unique['org_zipcode'].replace(zip_4, zip_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pi_unique['org_zipcode'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUNS numbers\n",
    "The DUNS number should be a 9-digit number that uniquely identifies an organization. However, the DUNS numbers of organizations changed between 2008 to 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[(pi_unique['org_name'].str.contains('stanford', na = False)) & ((pi_unique['fy'] == '2008') | (pi_unique['fy'] == '2009'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DUNS number is also not unique between 2008 and 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_duns'] == '009214214']['org_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization names and DUNS change between 2008 and 2009, and the DUNS are not unique between the two epochs. It will be difficult to cross reference each institution across years. For the first pass, we will only analyze grants from 2009 and later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi_unique = pi_unique.ix[pi_unique['fy'] > '2008']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUNS numbers of different lengths\n",
    "DUNS numbers should be 9 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pi_unique['org_duns'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_duns'].str.len() == 8.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_duns'].str.len() == 7.0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like most of the 8 and 7 digit DUNS numbers are missing leading zeros. Assume this is the case and add leading zeros to DUNS numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = add_zero_duns(pi_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-organize columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_cols = pi_unique.columns.tolist()\n",
    "new_cols = old_cols[0:1] + old_cols[-3:-1] + old_cols[-1:] + old_cols[3:4] + old_cols[1:2] + old_cols[4:5] + old_cols[5:6] + old_cols[2:3]\n",
    "pi_unique = pi_unique[new_cols]\n",
    "pi_unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to NIH's description, multiple DUNS are separated by a semi-colon. There are only two groups where multiple DUNS are listed, those with 19 characters and those with 20 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_duns'].str.len() == 20.0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_duns'].str.len() == 19.0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For organizations where two DUNS are listed, it seems that both DUNS are used to identify the organization. The only difference between a DUNS with 20 characters and 19 characters is a space after the ';'. Add a space to the 19-length DUNS and replace these values in the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the DUNS numbers from pi_unique where the length of the DUNS is 19\n",
    "len19 = pi_unique.ix[pi_unique['org_duns'].str.len() == 19.0]['org_duns'].values.tolist()\n",
    "\n",
    "#add a space after the semi-colon\n",
    "len19_new = []\n",
    "for i in range(len(len19)):\n",
    "    len19_new.append(len19[i][:10] + ' ' + len19[i][10:])\n",
    "\n",
    "#replace the original DUNS of 19 characters\n",
    "pi_unique['org_duns'] = pi_unique['org_duns'].replace(len19, len19_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicates by pi_id and org_duns, as a PI can move between institutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.shape\n",
    "pi_unique = pi_unique.drop_duplicates('pi_ids org_duns'.split())\n",
    "pi_unique.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing information\n",
    "First check the entries where no country is listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_country'].isnull()]['org_name'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'clinical sciences' and 'clinical center' likely refer to the same center, as clinical sciences is listed in years < 2012 and afterwards clinical center is listed.\n",
    "* Replace 'environmental health sciences' with 'national institute of environmental health sciences'\n",
    "* Correct single entries\n",
    "* Drop the 'children s hospital medic' entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = ['clinical sciences', 'environmental health sciences', 'iit resch institute',\n",
    "    'institute for defense ana', 'california univ los angel']\n",
    "b = ['clinical center', 'national institute of environmental health sciences', 'iit research institute',\n",
    "    'institute for defense analyses, inc', 'university of california los angeles']\n",
    "pi_unique.replace(a, b, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_name'].str.contains('danmarks tekniske univers', na = False)] = \\\n",
    "pi_unique.ix[pi_unique['org_name'].str.contains('danmarks tekniske univers', na = False)]\\\n",
    ".fillna({'org_city':'Kongens Lyngby', 'org_country':'Denmark'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No information available for the entry 'children s hospital medic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop = pi_unique.ix[pi_unique['org_name'] == 'children s hospital medic'].index\n",
    "pi_unique.drop(to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing organization information\n",
    "Based on unique DUNS numbers, fill in:\n",
    "* Organization name\n",
    "* City, state, zipcode\n",
    "* Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill NaNs, we are filtering by DUNS numbers. Therefore first pull out organizations where the DUNS is not listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_duns = pi_unique.ix[pi_unique['org_duns'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = fill_missing(pi_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace information\n",
    "A lot of entries have incorrect information entered (wrong zip codes in particular). We assume that the mistakes are less common than the correct entry. Therefore find the most common entry and fill the other entries accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pi_unique.to_csv('intermediate.csv', index = False, compression = 'gzip')\n",
    "#pi_unique = pd.read_csv('intermediate.csv', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = replace_info(pi_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding dummy DUNS numbers\n",
    "First add back grants where the DUNS number was not listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = pi_unique.append(null_duns)\n",
    "pi_unique.sort_index(inplace = True)\n",
    "pi_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_duns.isnull().sum()\n",
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean organization names by adding a space after the '&' symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "and_names = pd.DataFrame()\n",
    "and_names['original'] = pi_unique.loc[pi_unique['org_name'].str.contains(' &[^ ]', na = False)]['org_name']\n",
    "and_names['with_space'] = pi_unique.loc[pi_unique['org_name'].str.contains(' &[^ ]', na = False)]['org_name']\\\n",
    ".str.replace('&', '& ')\n",
    "\n",
    "and_names = and_names.drop_duplicates()\n",
    "\n",
    "no_space = and_names['original'].tolist()\n",
    "with_space = and_names['with_space'].tolist()\n",
    "pi_unique.replace(no_space, with_space, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in missing DUNS numbers for those entries where the DUNS number is listed in other rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = fill_missing(pi_unique, col_filter = 'org_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dummy DUNS numbers to those organizations where the DUNS are not listed. **Caveat:** If the organization name is misspelled or incorrectly entered, then a unique DUNS will be generated for that entry even though the organization is already listed in the organization. Matching by string similarity will be difficult. Matching by zip codes are also unreliable because zip codes seem particularly prone to incorrect entry (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = add_dummy_duns(pi_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing NIH information\n",
    "\n",
    "Most grants without a listed country seem to be associated with different NIH centers. Most information of these organizations, that is, DUNS number, city, state and zipcode in addition to country, are missing. There are some NIH centers where all this information is available; however, the name of the center is listed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_country'].isnull()]['org_name'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_zipcode'].str.contains('20892', na = False)]['org_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace/fill the corresponding NIH centers in the pi_unique dataframe with the information above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_nih_names = {\n",
    "    'national institute of allergy and infectious diseases':'u.s. national inst allergy & infect dis',\n",
    "    'child health and human development':'u.s. national inst/child hlth/human dev',\n",
    "    'diabetes, digestive, kidney diseases':'u.s. national inst diabetes/digst/kidney',\n",
    "    'national institute of mental health':'u.s. national institute of mental health',\n",
    "    'neurological disorders and stroke':'u.s. national inst/neuro/ds/stroke',\n",
    "    'alcohol abuse and alcoholism':'u.s. national inst alcohol ab/alcoholism',\n",
    "    'heart, lung, and blood institute':'u.s. national heart lung and blood inst'\n",
    "}\n",
    "\n",
    "pi_unique = replace_nih_info(pi_unique, dict_nih_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding missing NIH information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.ix[pi_unique['org_country'].isnull()]['org_name'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No information about NIH city, state, country and zipcode is listed for the remaining NIH centers. Add this information as bethesda, md, united states and 20892, respectively. **Note:** This address may not be exact, as some NIH institutes/centers may be located elsewhere, but this information will represent general NIH information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique = add_nih_info(pi_unique, col = 'org_city', replace_with = 'bethesda')\n",
    "pi_unique = add_nih_info(pi_unique, col = 'org_state', replace_with = 'md')\n",
    "pi_unique = add_nih_info(pi_unique, col = 'org_zipcode', replace_with = '20892')\n",
    "pi_unique = add_nih_info(pi_unique, col = 'org_country', replace_with = 'united states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing zip codes for USA entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_zip = pi_unique.ix[(pi_unique['org_country'] == 'united states') & pi_unique['org_zipcode'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_zip.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_zip['org_duns'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be possible to fill the missing zip codes via an automated Google search (see http://stackoverflow.com/questions/37083058/programmatically-searching-google-in-python-using-custom-search). This will likely be unnecessary because only about 400 unique organizations are missing zip codes. When we analyze and/or plot geospatial data we can decide whether to fill in these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pi_unique.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pi_unique.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_unique.to_csv('pi_info.csv', index = False, compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
